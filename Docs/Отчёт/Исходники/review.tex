\section{Обзор.}
%Или лучше локальные цели???

В рамках данной работы ставится цель разработки прототипа генератора анализаторов, удовлетворяющего основным перечисленным требованиям и предоставляющего, в то же время, ставшие привычными средства автоматизации трансляции (дополнение грамматики атрибутами, средства автоматического восстановления после ошибок, средства диагностики).

%Стоит задача разработки анализатора для произвольной контекстно свободных грамматик на платформе .NET и реализации его на %функциональном языке программирования F\#. Необходимость такой разработки была обоснована выше. 
         
Необходимость поддержки неоднозначных грамматик (на практике, как правило,грамматики лишь «слегка» неоднозначные) предопределила выбор алгоритма GLR в качестве анализатора. Работу алгоритма GLR можно рассматривать как параллельное исполнение набора LR-анализаторов. При этом данный набор дополняется процедурой управления магазинами, оптимизирующей представление магазинов путем их «склеивания» и «расклеивания», что позволяет хранить и строить параллельные выводы в рамках одного LR-анализатора, лишь в моменты их различия добавляя параллельный анализатор.

Оказалось, что весьма наглядно такой алгоритм может быть представлен в виде двух взаимно-рекурсивных функций (рекурсивно-восходящий алгоритм, recursive ascent). При этом расклеивание магазина получается естественным образом как ветвление в одной из функций, а обратное склеивание может быть реализовано как кэширование результата функции. В рассматриваемом проекте данный алгоритм реализован на функциональном языке F\# в среде .NET, при этом склеивание реализовано с помощью конструкции замыкания.

Естественным образом получается и поддержка регулярных выражений в правых частях правил (EBNF-грамматики). Для этого правая часть правила представляется как конечный автомат. LR-ситуация в таком случае может быть представлена парой:правило (нетерминал+КА) и номер состояния (соответствует позиции маркера в классическом определении). Проблемы определения левой границы отрезка в магазине, соответствующего текущему правилу, в данном подходе не существует, так как стек вызовов рекурсивных функций хранит информацию о начале анализа по правилу.

Автоматизированный реинжиниринг программ выдвигает особые требования к инструменту анализа и языку спецификаций трансляции \cite{Diploma}. Используемые в разрабатываемом инструменте грамматики YARD удовлетворяют основным таким требованиям.  Поэтому наибольший интерес сейчас представляет анализ внутренних алгоритмов анализа в существующих инструментах. 
          
Предпочтительным алгоритмам анализа является алгоритм разбора произвольной контекстно свободной грамматики. Поэтому нужно рассмотреть инструменты, основанные на этом алгоритме. Важен способ реализации алгоритма, так как существуют несколько альтернатив: алгоритм Томиты (GLR-алгоритм), алгоритм Эрли (Early), рекурсивно-восходящий алгоритм. Так-же следует обратить преобразования грамматики, необходимые для  построения анализатора. 
       
В настоящее время существуют следующие инструменты основанные на GLR-алгоритме.
\begin{itemize}
\item
 ASF+SDF \cite{ASF+SDF} (Algebraic Specification Formalism + Syntax Definition Formalism)
- генератор с широкими возможностями, но достаточно сложным входным
языком. Является SGLR-инструментом (Scannerless, Generalized-LR).
\item
 Bison \cite{Bison} - развитие инструмента YACC. Все грамматики, созданные
для оригинального YACC, будут работать и в Bison. Является одним
из самых популярных и совершенных "потомков" YACC. При включении
соответствующей опции использует GLR-алгоритм (по умолчанию LALR).
\item
 Elkhound \cite{Elkhound} - позиционируется как быстрый и удобный GLR-инструмент,
созданный в университете Беркли (США), тем не менее обладает достаточно
"бедным" входным языком (например, он не поддерживает конструкций
расширенной формы Бэкуса-Наура).
\end{itemize}

В работе \cite{Diploma} проведён подробный анализ этих инструментов. Подводя итог, можно сказать, что на текущий момент нет инструмента, полностью удовлетворяющего требованиям автоматизированного реинжиниринга программ.

Так же нас будет интересовать такой инструмент как Jade, являющийся генератором рекурсивно-восходящих парсеров.
       
Jade это генератор рекурсивно-восходящих LALR(1) парсеров с целевым языком С. Его подробное описание приводится в статье \cite{Jade}. При реализации данного инструмента появилась проблема объёма кода целевого парсера. Так как при построении детерминированного парсера необходимо генерировать процедуры для каждого состояния, то объём кода быстро растёт, с ростом количества правил в грамматике. Так для языка Java, по расчётам, приведённым в статье\cite{Jade}, объём кода составляет примерно 4 мегабайта. В Jade  эта проблема решается путём создания глобальной структуры(массива состояний), где хранится информация, позволяющая переиспользовать процедуры. (Подробнее об этом можно прочесть в статье \cite{Jade}). 

