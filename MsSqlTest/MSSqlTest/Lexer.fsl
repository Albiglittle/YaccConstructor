{
//  UserLexer.fs contains simple lexer for testing.
//
//  for build:  fslex Lexer.fsl --unicode -o Lexer.fs
//
//  Copyright 2010, 2011, 2011 Semen Grigorev <rsdpisuy@gmail.com>
//
//  This file is part of YaccConctructor.
//
//  YaccConstructor is free software:you can redistribute it and/or modify
//  it under the terms of the GNU General Public License as published by
//  the Free Software Foundation, either version 3 of the License, or
//  (at your option) any later version.
//
//  This program is distributed in the hope that it will be useful,
//  but WITHOUT ANY WARRANTY; without even the implied warranty of
//  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
//  GNU General Public License for more details.
//
//  You should have received a copy of the GNU General Public License
//  along with this program.  If not, see <http://www.gnu.org/licenses/>.

module Lexer_alt
open Microsoft.FSharp.Text.Lexing
open Microsoft.FSharp.Text
open Yard.Generators.GNESCCGenerator
open Yard.Generators.GNESCCGenerator.Tables
open Microsoft.FSharp.Reflection
open LexerHelper

exception IdentToken
let getKwToken (name: string) = 
  try
    match name.ToUpper() with
    | "SELECT" -> T_KW_SELECT
    | "FROM"   -> T_KW_FROM
    | _        -> raise IdentToken
  with
    | IdentToken -> T_IDENT

(*    let nameToUnionCtor (uci:UnionCaseInfo) = (uci.Name, FSharpValue.PreComputeUnionConstructor(uci))
    let ucis = FSharpType.GetUnionCases(typeof<token>) 
                    |> Array.map nameToUnionCtor                       
                    |> dict
    fun (name:string) startPos endPos ->
    let upperName = "KW_" + name.ToUpper()
    let (present, ctor) = ucis.TryGetValue(upperName) 
    if present then
        Some(ctor [| SourceText.ofTuple(name, (startPos, endPos)) |] :?>token)
    else
        None *)

let comment_depth = ref 0
let startPos = ref Position.Empty
let str_buf = new System.Text.StringBuilder()

let appendBuf (str:string) = str_buf.Append(str) |> ignore
let clearBuf () = str_buf.Clear() |> ignore
  
let makeIdent notKeyWord name =
(*    let prefix = if name.Length>=2 then name.[0..1] else ""
    if prefix = "@@" then GLOBALVAR(SourceText.ofTuple(name,(startPos,endPos)))
    else if prefix = "##" then GLOBALTEMPOBJ(SourceText.ofTuple(name,(startPos,endPos)))
    else if name.[0] = '@' then LOCALVAR(SourceText.ofTuple(name,(startPos,endPos)))
    else if name.[0] = '#' then TEMPOBJ(SourceText.ofTuple(name,(startPos,endPos)))
    else *) 
    if notKeyWord then T_IDENT
    else 
        getKwToken name 


type MyLexeme (tag,_value) =
    member self.MValue = _value
    interface ILexeme with    
       member self.tag = tag
       member self.CompareTo x =  compare (hash self) (hash x)
    end

 }

let anything = ['a'-'z' 'A'-'Z' '0'-'9' '\n' '\r' ' ' ] + 

let eol = '\r' | '\n' | '\r' '\n' (* See script.sql position (4560,27) *)
let whitespaces = [' '  '\t']+
let ident_start_char  = ['A'-'Z' 'a'-'z' '_' '@' '#' 'а'-'я' 'А'-'Я' ] 
let ident_body_char  = ['A'-'Z' 'a'-'z' '_' '0'-'9' '@' '#' '$' 'а'-'я' 'А'-'Я' ] 
// Разобраться с идентификаторами cyrillic с,а (885574,_) (1004524)
let ident = ident_start_char ident_body_char*
let decnumber = ['0'-'9']+ 
let hexnumber = "0x" ['0'-'9' 'a'-'f' 'A'-'F']+
let label = ident ':'


rule tokens = parse
 | eol   { tokens lexbuf }
 | whitespaces { tokens lexbuf }
 | ident {  let l = LexBuffer<_>.LexemeString(lexbuf) in
            MyLexeme(l |> (makeIdent false) |> getTag, l)
         }
 
 | eof  {MyLexeme(Constants.gnesccEndStreamTag, LexBuffer<_>.LexemeString(lexbuf))}
and multiline_comment = parse
  | "/*" 
    { incr comment_depth; appendBuf(LexBuffer<_>.LexemeString(lexbuf)); multiline_comment lexbuf}
  | "*/"
    { decr comment_depth; 
      if !comment_depth = 0 then 
        MyLexeme(getTag T_COMMENT, "somecomment")
      else 
        appendBuf(LexBuffer<_>.LexemeString(lexbuf)); multiline_comment lexbuf 
    }
  | eol {lexbuf.EndPos <- lexbuf.EndPos.NextLine; appendBuf(LexBuffer<_>.LexemeString(lexbuf)); multiline_comment lexbuf }
  | eof { failwith "unclosed comment in the end of file" }
  | [^ '\r' '\n' '*' '/']+ { appendBuf(LexBuffer<_>.LexemeString(lexbuf)); multiline_comment lexbuf } 
  | _ { appendBuf(LexBuffer<_>.LexemeString(lexbuf)); multiline_comment lexbuf } 

{

type Lexer(lb) = 
    let locBuf = ref []
    interface ILexer with        
    
       member self.Get pos = 
        let l = !locBuf |> List.length
        if l >= pos
        then (!locBuf).[l-pos]
        else
            let t = (tokens lb) :> ILexeme
            locBuf := t :: !locBuf
            t      
    end

}